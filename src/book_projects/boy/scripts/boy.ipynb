{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Papa and Mama\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "My father, Harald Dahl, was a Norwegian who came from a small town near Oslo, called Sarpsborg. His own father, my grandfather, was a fairly prosperous merchant who owned a store in Sarpsborg and traded in just about everything from cheese to chicken-wire.\n",
      "\n",
      "\n",
      "I am writing these words in 1984, but this grandfather of mine was born, believe it or not, in 1820, shortly after Wellington had defeated Napoleon at Waterloo. If my grandfather had been alive today he would have been one hundred and sixty-four years old. My father would have been one hundred and twenty-one. Both my father and my grandfather were late starters so far as children were concerned.\n",
      "\n",
      "\n",
      "When my father was fourteen, which is still more than one hundred years ago, he was up on the roof of the family house replacing some loose tiles when he slipped and fell. He broke his left arm below the elbow. Somebody ran to fetch the doctor, and half an hour later this gentleman made a majestic and drunken arrival in his horse-drawn buggy. He was so drunk that he mistook the fractured elbow for a dislocated shoulder.\n",
      "\n",
      "\n",
      "‘We’ll soon put this back into place!’ he cried out, and two men were called off the street to help with the pulling. They were instructed to hold my father by the waist while the doctor grabbed him by the wrist of the broken arm and shouted, ‘Pull men, pull! Pull as hard as you can!’\n",
      "\n",
      "\n",
      "The pain must have been excruciating. The victim screamed, and his mother, who was watching the performance in horror, shouted ‘Stop!’ But by then the pullers had done so much damage that a splinter of bone was sticking out through the skin of the forearm.\n",
      "\n",
      "\n",
      "This was in 1877 and orthopaedic surgery was not what it is today. So they simply amputated the arm at the elbow, and for the rest of his life my father had to manage with one arm. Fortunately, it was the left arm that he lost and gradually, over the years, he taught himself to do more or less anything he wanted with just the four fingers and thumb of his right hand. He could tie a shoelace as quickly as you or me, and for cutting up the food on his plate, he sharpened the bottom edge of a fork so that it served as both knife and fork all in one. He kept his ingenious instrument in a slim leather case and carried it in his pocket wherever he went. The loss of an arm, he used to say, caused him only one serious inconvenience. He found it impossible to cut the top off a boiled egg.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "My father was a year or so older than his brother Oscar, but they were exceptionally close, and soon after they left school, they went for a long walk together to plan their future. They decided that a small town like Sarpsborg in a small country like Norway was no place in which to make a fortune. So what they must do, they agreed, was go away to one of the big countries, either to England or France, where opportunities to make good would be boundless.\n",
      "\n",
      "\n",
      "Their own father, an amiable giant nearly seven foot tall, lacked the drive and ambition of his sons, and he refused to support this tomfool idea. When he forbade them to go, they ran away from home, and somehow or other the two of them managed to work their way to France on a cargo ship.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "From Calais they went to Paris, and in Paris they agreed to separate because each of them wished to be independent of the other. Uncle Oscar, for some reason, headed west for La Rochelle on the Atlantic coast, while my father remained in Paris for the time being.\n",
      "\n",
      "\n",
      "The story of how these two brothers each started a totally separate business in different countries and how each of them made a fortune is interesting, but there is no time to tell it here except in the briefest manner.\n",
      "\n",
      "\n",
      "Take my Uncle Oscar first. La Rochelle was then, and still is, a fishing port. By the time he was forty he had become the wealthiest man in town. He owned a fleet of trawlers called ‘Pêcheurs d’Atlantique’ and a large canning factory to can the sardines his trawlers brought in. He acquired a wife from a good family and a magnificent town house as well as a large château in the country. He became a collector of Louis XV furniture, good pictures and rare books, and all these beautiful things together with the two properties are still in the family. I have not seen the château in the country, but I was in the La Rochelle house a couple of years ago and it really is something. The furniture alone should be in a museum.\n",
      "\n",
      "\n",
      "While Uncle Oscar was bustling around in La Rochelle, his one-armed brother Harald (my own father) was not sitting on his rump doing nothing. He had met in Paris another young Norwegian called Aadnesen and the two of them now decided to form a partnership and become shipbrokers. A shipbroker is a person who supplies a ship with everything it needs when it comes into port – fuel and food, ropes and paint, soap and towels, hammers and nails, and thousands of other tiddly little items. A shipbroker is a kind of enormous shopkeeper for ships, and by far the most important item he supplies to them is the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fuel on which the ship’s engines run. In those days fuel meant only one thing. It meant coal. There were no oil-burning motorships on the high seas at that time. All ships were steamships and these old steamers would take on hundreds and often thousands of tons of coal in one go. To the shipbrokers, coal was black gold.\n",
      "\n",
      "\n",
      "My father and his new-found friend, Mr Aadnesen, understood all this very well. It made sense they told each other, to set up their shipbroking business in one of the great coaling ports of Europe. Which was it to be? The answer was simple. The greatest coaling port in the world at that time was Cardiff, in South Wales. So off to Cardiff they went, these two ambitious young men, carrying with them little or no luggage. But my father had something more delightful than luggage. He had a wife, a young French girl called Marie whom he had recently married in Paris.\n",
      "\n",
      "\n",
      "In Cardiff, the shipbroking firm of ‘Aadnesen & Dahl’ was set up and a single room in Bute Street was rented as an office. From then on, we have what sounds like one of those exaggerated fairy-stories of success, but in reality it was the result of tremendous hard and brainy work by those two friends. Very soon ‘Aadnesen & Dahl’ had more business than the partners could handle alone. Larger office space was acquired and more staff were engaged. The real money then began rolling in. Within a few years, my father was able to buy a fine house in the village of Llandaff, just outside Cardiff, and there his wife Marie bore him two children, a girl and a boy. But tragically, she died after giving birth to the second child.\n",
      "\n",
      "\n",
      "When the shock and sorrow of her death had begun to subside a little, my father suddenly realized that his two small children ought at the very least to have a stepmother to care for them. What is more, he felt terribly lonely. It was quite obvious that he must try to find himself another wife. But this was easier said than done for a Norwegian living in South Wales who didn’t know very many people. So he decided to take a holiday and travel back to his own country, Norway, and who knows, he might if he was lucky find himself a lovely new bride in his own country.\n",
      "\n",
      "\n",
      "Over in Norway, during the summer of 1911, while taking a trip in a small coastal steamer in the Oslofjord, he met a young lady called Sofie Magdalene Hesselberg. Being a fellow who knew a good thing when he saw one, he proposed to her within a week and married her soon after that.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mama Engaged\n",
      "\n",
      "\n",
      "Harald Dahl took his Norwegian wife on a honeymoon in Paris, and after that back to the house in Llandaff. The two of them were deeply in love and blissfully happy, and during the next six years she bore him four children, a girl,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Me at 8 months\n",
      "\n",
      "\n",
      "another girl, a boy (me) and a third girl. There were now six children in the family, two by my father’s first wife and four by his second. A larger and grander house was needed and the money was there to buy it.\n",
      "\n",
      "\n",
      "So in 1918, when I was two, we all moved into an imposing country mansion beside the village of Radyr, about eight miles west of Cardiff. I remember it as a mighty house with turrets on its roof and with majestic lawns and terraces all around it. There were many acres of farm and woodland, and a number of cottages for the staff. Very soon, the meadows were full of milking cows and the sties were full of pigs and the chicken-run was full of chickens. There were several massive shire-horses for pulling the ploughs and the hay-wagons, and there was a ploughman and a cowman and a couple of gardeners and all manner of servants in the house itself. Like his brother Oscar in La Rochelle, Harald Dahl had made it in no uncertain manner.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The house at Radyr\n",
      "\n",
      "\n",
      "But what interests me most of all about these two brothers, Harald and Oscar, is this. Although they came from a simple unsophisticated small-town family, both of them, quite independently of one another, developed a powerful interest in beautiful things. As soon as they could afford it, they began to fill their houses with lovely paintings and fine furniture. In addition to that, my father became an expert gardener and above all a collector of alpine plants. My mother used to tell me how the two of them would go on expeditions up into the mountains of Norway and how he would frighten her to death by climbing one-handed up steep cliff-faces to reach small alpine plants growing high up on some rocky ledge. He was also an accomplished wood-carver, and most of the mirror-frames in the house were his own work. So indeed was the entire mantelpiece around the fireplace in the living-room, a splendid design of fruit and foliage and intertwining branches carved in oak.\n",
      "\n",
      "\n",
      "He was a tremendous diary-writer. I still have one of his many notebooks from the Great War of 1914–18. Every single day during those five war years he would write several pages of comment and observation about the events of the time. He wrote with a pen and although Norwegian was his mother-tongue, he always wrote his diaries in perfect English.\n",
      "\n",
      "\n",
      "He harboured a curious theory about how to develop a sense of beauty in the minds of his children. Every time my mother became pregnant, he would wait until the last three months of her pregnancy and then he would announce to her that ‘the glorious walks’ must begin. These glorious walks consisted of him taking her to places of great beauty in the countryside and walking with her for about an hour each day so that she could absorb the splendour of the surroundings. His theory was that if the eye of a pregnant woman was constantly observing the beauty of nature, this beauty would somehow become transmitted to the mind of the unborn baby within her womb and that baby would grow up to be a lover of beautiful things. This was the treatment that all of his children received before they were born.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A letter from Papa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "________________\n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "from general_functions.file_operations import read_txt_file\n",
    "data_folder = \"../data/\"\n",
    "text_file_location = data_folder + \"extracted_chapters/Chapter_1.txt\"\n",
    "text = read_txt_file(text_file_location)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run BookNLP pipeline, create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n",
      "The following BookNLP files already exist in the output directory:\n",
      "../data/booknlp_output/boy\\boy.book\n",
      "../data/booknlp_output/boy\\boy.book.html\n",
      "../data/booknlp_output/boy\\boy.entities\n",
      "../data/booknlp_output/boy\\boy.quotes\n",
      "../data/booknlp_output/boy\\boy.supersense\n",
      "../data/booknlp_output/boy\\boy.tokens\n"
     ]
    }
   ],
   "source": [
    "## BookNLP Stuff\n",
    "from general_functions.booknlp import run_booknlp\n",
    "\n",
    "# Constants \n",
    "# Input file to process\n",
    "input_file=\"../data/dahl-boy-4.txt\"\n",
    "# Output directory to store resulting files in \n",
    "output=\"../data/booknlp_output/boy/\"\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "id=\"boy\"\n",
    "pipeline=\"entity,quote,supersense,event,coref\"\n",
    "\n",
    "#Call functions\n",
    "run_booknlp(input_file_location=input_file, output_directory=output, book_id=id,pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1 Papa and Mama\n",
      "Mama Engaged\n",
      "Me at 8 months\n",
      "________________\n",
      "Me and Mama Radyr\n",
      "Llandaff Cathedral\n",
      "â€˜What is ratitis, Daddy?â€™ young Thwaites had asked.\n",
      "________________\n",
      "CHAPTER 4 The Great Mouse Plot\n",
      "Thwaites hesitated. They all looked at me.\n",
      "â€˜Of course I did!â€™ I said.\n",
      "CHAPTER 5 Mr Coombes\n",
      "â€˜Thereâ€™s the mouse!â€™ someone else shouted.\n",
      "Nobody answered me.\n",
      "Nobody answered him.\n",
      "â€˜What?â€™ we said. â€˜What happens?â€™\n",
      "â€˜Shut up,â€™ Mr Coombes said.\n",
      "â€˜Youâ€™re quite sure?â€™ Mr Coombes said.\n",
      "â€˜Enter!â€™\n",
      "â€˜Bend over,â€™ Mr Coombes said.\n",
      "â€˜Tighter, boy, tighter!â€™ Mr Coombes snapped out. â€˜Touch the ground!â€™\n",
      "â€˜Ow-w-w-w-w!â€™ yelled Thwaites.\n",
      "â€˜Next!â€™ snapped Mr Coombes.\n",
      "â€˜What did you say?â€™\n",
      "CHAPTER 7Going to Norway\n",
      "Bestemama and Bestepapa (and Astri)\n",
      "Me, Alfhild, Else â€“ Norway 1924\n",
      "â€˜What are they?â€™ I asked her.\n",
      "The Loony Bin!\n",
      "CHAPTER  12 The Matron\n",
      "CHAPTER  13 Homesickness\n",
      "â€˜Whatâ€™s it for?â€™ I asked her.\n",
      "â€˜It hurts, Matron,â€™ I moaned. â€˜Oh, it hurts so much! Just here!â€™\n",
      "â€˜It hurts,â€™ I moaned.\n",
      "â€˜Yes,â€™ she said.\n",
      "â€˜Sick,â€™ I said.\n",
      "CHAPTER 15 Captain Hardcastle\n",
      "MASTER. What is it?\n",
      "MASTER. Yes, what is it?\n",
      "MASTER. A what?\n",
      "MASTER. What Prep are you doing tonight?\n",
      "â€˜Enter!â€™\n",
      "â€˜I wouldnâ€™t if I were you.â€™\n",
      "â€˜Bend over.â€™\n",
      "â€˜Where is he now?â€™\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\src\\book_projects\\boy\\scripts\\boy.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m paragraphs \u001b[39m=\u001b[39m read_and_split_story(story_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m#for idx, para in enumerate(paragraphs[:10]):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m#    print(f\"Paragraph {idx + 1}:\\n{para}\\n{'-'*50}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39m# Analyze the sentiment of paragraphs\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m results \u001b[39m=\u001b[39m analyze_paragraphs(paragraphs, lexicon_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m#for para_index, (avg_score, neg_sentence) in results.items():\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m#    print(f\"Paragraph {para_index}:\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m#    print(f\"  Average Score: {avg_score}\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# Save results to a JSON file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m write_to_json(results, output_path)\n",
      "\u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\src\\book_projects\\boy\\scripts\\boy.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, para \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(paragraphs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     sentence_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(para)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     max_sent \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raquel%20Coelho/Desktop/elalytics-data-processing/src/book_projects/boy/scripts/boy.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     max_score \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m--> 126\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[0;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[39mbool\u001b[39m\n\u001b[0;32m     34\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[0;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 36\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[0;32m     37\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Padded):\n\u001b[0;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ragged_forward\u001b[39m(\n\u001b[0;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[39mbool\u001b[39m\n\u001b[0;32m     89\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m     Y, get_dX \u001b[39m=\u001b[39m layer(Xr\u001b[39m.\u001b[39;49mdataXd, is_train)\n\u001b[0;32m     93\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYr: Ragged) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ragged:\n\u001b[0;32m     94\u001b[0m         \u001b[39mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[39m.\u001b[39mdataXd), dYr\u001b[39m.\u001b[39mlengths)\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\concatenate.py:65\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(OutT, data_r), backprop\n\u001b[0;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     data_a, backprop \u001b[39m=\u001b[39m _array_forward(model, X, Ys, callbacks, is_train)\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(OutT, data_a), backprop\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\thinc\\layers\\concatenate.py:73\u001b[0m, in \u001b[0;36m_array_forward\u001b[1;34m(model, X, Ys, callbacks, is_train)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_forward\u001b[39m(\n\u001b[0;32m     70\u001b[0m     model: Model[InT, OutT], X, Ys: List, callbacks, is_train: \u001b[39mbool\u001b[39m\n\u001b[0;32m     71\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Array2d, Callable]:\n\u001b[0;32m     72\u001b[0m     widths \u001b[39m=\u001b[39m [Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m Y \u001b[39min\u001b[39;00m Ys]\n\u001b[1;32m---> 73\u001b[0m     output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mxp\u001b[39m.\u001b[39;49mhstack(Ys)\n\u001b[0;32m     75\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(d_output: Array2d) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m InT:\n\u001b[0;32m     76\u001b[0m         dY \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mas_contig(d_output[:, : widths[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\Raquel Coelho\\Desktop\\elalytics-data-processing\\.venv\\Lib\\site-packages\\numpy\\core\\shape_base.py:359\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, casting\u001b[39m=\u001b[39mcasting)\n\u001b[0;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Suspense chart \n",
    "\n",
    "#Required libraries \n",
    "import pandas as pd\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "lexicon_path = \"../data/NRC-VAD-Lexicon.csv\"\n",
    "story_path = \"../data/dahl-boy-4.txt\"\n",
    "output = \"../data/suspense.json\"\n",
    "\n",
    "\n",
    "# Load the English model for SpaCy; used for tokenizing the story into sentences/words\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Reads the lexicon data; returns it as dataframe\n",
    "def load_lexicon(file_path):\n",
    "    return pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "# Reads the story from file; splits it into paragraphs; returns a list of paragraphs\n",
    "def read_and_split_story(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    return [para.strip() for para in text.split(\"\\n\\n\") if para]\n",
    "\n",
    "# Calculates a score for each word in a sentence based on valence and arousal values from lexicon\n",
    "# Final score for the sentence is the average of all word scores\n",
    "# If the word doesn't exist in lexicon or isn't alphanumeric, it's skipped.\n",
    "def get_negative_valence_arousal_score(sentence, lexicon_df):\n",
    "    doc = nlp(sentence)\n",
    "    scores = []\n",
    "    for token in doc:\n",
    "        word = token.text\n",
    "        if not word.isalnum():\n",
    "            continue\n",
    "        word_data = lexicon_df.loc[lexicon_df['Word'] == word]\n",
    "        if not word_data.empty:\n",
    "            valence = word_data['Valence'].values[0]\n",
    "            arousal = word_data['Arousal'].values[0]\n",
    "            negative_valence = 1 - valence\n",
    "            scores.append(negative_valence + arousal)\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Analyzes each paragraph in the story. Tokenizes each paragraph into sentences\n",
    "# Computes sentiment for each sentence\n",
    "# Result for each paragraph is the average sentiment score of its sentences \n",
    "# + sentence with the highest score\n",
    "def analyze_paragraphs(paragraphs, lexicon_df):\n",
    "    para_scores = {}\n",
    "    for index, para in enumerate(paragraphs):\n",
    "        sentence_scores = []\n",
    "        doc = nlp(para)\n",
    "        max_sent = \"\"\n",
    "        max_score = -100\n",
    "        for sent in doc.sents:\n",
    "            score = get_negative_valence_arousal_score(sent.text, lexicon_df)\n",
    "            if score and score > max_score:\n",
    "                max_score = score\n",
    "                max_sent = sent.text\n",
    "            sentence_scores.append(score)\n",
    "        sentence_scores = [score for score in sentence_scores if score is not None]\n",
    "        if not sentence_scores:\n",
    "            print(para)\n",
    "            continue\n",
    "        average_score = sum(sentence_scores) / len(sentence_scores)\n",
    "        para_scores[index + 1] = [average_score, max_sent]\n",
    "    return para_scores\n",
    "\n",
    "# Saves a python dictionary as JSON file\n",
    "def write_to_json(data, output_path):\n",
    "    with open(output_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file)\n",
    "\n",
    "# Main script \n",
    "\n",
    "# Load lexicon data\n",
    "lexicon_df = load_lexicon(lexicon_path)\n",
    "#print(lexicon_df.head())\n",
    "\n",
    "# Extract paragraphs from the story\n",
    "paragraphs = read_and_split_story(story_path)\n",
    "#for idx, para in enumerate(paragraphs[:10]):\n",
    "#    print(f\"Paragraph {idx + 1}:\\n{para}\\n{'-'*50}\")\n",
    "\n",
    "# Analyze the sentiment of paragraphs\n",
    "results = analyze_paragraphs(paragraphs, lexicon_df)\n",
    "#for para_index, (avg_score, neg_sentence) in results.items():\n",
    "#    print(f\"Paragraph {para_index}:\")\n",
    "#    print(f\"  Average Score: {avg_score}\")\n",
    "#    print(f\"  Most Negative Sentence: {neg_sentence}\")\n",
    "#    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# Save results to a JSON file\n",
    "write_to_json(results, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
